{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import matplotlib\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects import postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# import data\n",
    "# ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import crash data\n",
    "crashes_raw = gpd.read_file('https://opendata.arcgis.com/datasets/70392a096a8e431381f1f692aaa06afd_24.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "CRIMEID\n",
      "CCN\n",
      "REPORTDATE\n",
      "ROUTEID\n",
      "MEASURE\n",
      "OFFSET\n",
      "STREETSEGID\n",
      "ROADWAYSEGID\n",
      "FROMDATE\n",
      "TODATE\n",
      "MARID\n",
      "ADDRESS\n",
      "LATITUDE\n",
      "LONGITUDE\n",
      "XCOORD\n",
      "YCOORD\n",
      "WARD\n",
      "EVENTID\n",
      "MAR_ADDRESS\n",
      "MAR_SCORE\n",
      "MAJORINJURIES_BICYCLIST\n",
      "MINORINJURIES_BICYCLIST\n",
      "UNKNOWNINJURIES_BICYCLIST\n",
      "FATAL_BICYCLIST\n",
      "MAJORINJURIES_DRIVER\n",
      "MINORINJURIES_DRIVER\n",
      "UNKNOWNINJURIES_DRIVER\n",
      "FATAL_DRIVER\n",
      "MAJORINJURIES_PEDESTRIAN\n",
      "MINORINJURIES_PEDESTRIAN\n",
      "UNKNOWNINJURIES_PEDESTRIAN\n",
      "FATAL_PEDESTRIAN\n",
      "TOTAL_VEHICLES\n",
      "TOTAL_BICYCLES\n",
      "TOTAL_PEDESTRIANS\n",
      "PEDESTRIANSIMPAIRED\n",
      "BICYCLISTSIMPAIRED\n",
      "DRIVERSIMPAIRED\n",
      "TOTAL_TAXIS\n",
      "TOTAL_GOVERNMENT\n",
      "SPEEDING_INVOLVED\n",
      "NEARESTINTROUTEID\n",
      "NEARESTINTSTREETNAME\n",
      "OFFINTERSECTION\n",
      "INTAPPROACHDIRECTION\n",
      "LOCATIONERROR\n",
      "LASTUPDATEDATE\n",
      "MPDLATITUDE\n",
      "MPDLONGITUDE\n",
      "MPDGEOX\n",
      "MPDGEOY\n",
      "BLOCKKEY\n",
      "SUBBLOCKKEY\n",
      "FATALPASSENGER\n",
      "MAJORINJURIESPASSENGER\n",
      "MINORINJURIESPASSENGER\n",
      "UNKNOWNINJURIESPASSENGER\n",
      "geometry\n"
     ]
    }
   ],
   "source": [
    "for column in crashes_raw:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import anc data\n",
    "ancs = gpd.read_file('https://opendata.arcgis.com/datasets/fcfbf29074e549d8aff9b9c708179291_1.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import all address points\n",
    "address_points = gpd.read_file('https://opendata.arcgis.com/datasets/aa514416aaf74fdc94748f1e56e7cc8a_0.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID_12\n",
      "OBJECTID\n",
      "SITE_ADDRESS_PK\n",
      "ADDRESS_ID\n",
      "ROADWAYSEGID\n",
      "STATUS\n",
      "SSL\n",
      "TYPE_\n",
      "ENTRANCETYPE\n",
      "ADDRNUM\n",
      "ADDRNUMSUFFIX\n",
      "STNAME\n",
      "STREET_TYPE\n",
      "QUADRANT\n",
      "CITY\n",
      "STATE\n",
      "FULLADDRESS\n",
      "SQUARE\n",
      "SUFFIX\n",
      "LOT\n",
      "NATIONALGRID\n",
      "ZIPCODE4\n",
      "XCOORD\n",
      "YCOORD\n",
      "STATUS_ID\n",
      "METADATA_ID\n",
      "OBJECTID_1\n",
      "ASSESSMENT_NBHD\n",
      "ASSESSMENT_SUBNBHD\n",
      "CFSA_NAME\n",
      "HOTSPOT\n",
      "CLUSTER_\n",
      "POLDIST\n",
      "ROC\n",
      "PSA\n",
      "SMD\n",
      "CENSUS_TRACT\n",
      "VOTE_PRCNCT\n",
      "WARD\n",
      "ZIPCODE\n",
      "ANC\n",
      "NEWCOMMSELECT06\n",
      "NEWCOMMCANDIDATE\n",
      "CENSUS_BLOCK\n",
      "CENSUS_BLOCKGROUP\n",
      "FOCUS_IMPROVEMENT_AREA\n",
      "SE_ANNO_CAD_DATA\n",
      "LATITUDE\n",
      "LONGITUDE\n",
      "ACTIVE_RES_UNIT_COUNT\n",
      "RES_TYPE\n",
      "ACTIVE_RES_OCCUPANCY_COUNT\n",
      "WARD_2002\n",
      "WARD_2012\n",
      "ANC_2002\n",
      "ANC_2012\n",
      "SMD_2002\n",
      "SMD_2012\n",
      "geometry\n"
     ]
    }
   ],
   "source": [
    "for column in address_points.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geojson version\n",
    "geojson_filename = Path(home, 'address_points.geojson')\n",
    "address_points.to_file(geojson_filename, driver='GeoJSON')\n",
    "data = open(geojson_filename, 'rb')\n",
    "s3.Bucket('dc-crash-bot-test').put_object(Key='address_points.geojson', Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import census blocks\n",
    "census_blocks = gpd.read_file('https://opendata.arcgis.com/datasets/a6f76663621548e1a039798784b64f10_0.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "BLKGRP\n",
      "BLOCK\n",
      "GEOID\n",
      "GEOID10\n",
      "ALAND10\n",
      "AWATER10\n",
      "P0010001\n",
      "P0010002\n",
      "P0010003\n",
      "P0010004\n",
      "P0010005\n",
      "P0010006\n",
      "P0010007\n",
      "P0010008\n",
      "OP000001\n",
      "OP000002\n",
      "OP000003\n",
      "OP000004\n",
      "P0020002\n",
      "P0020005\n",
      "P0020006\n",
      "P0020007\n",
      "P0020008\n",
      "P0020009\n",
      "P0020010\n",
      "OP00005\n",
      "OP00006\n",
      "OP00007\n",
      "OP00008\n",
      "P0030001\n",
      "P0030003\n",
      "P0030004\n",
      "P0030005\n",
      "P0030006\n",
      "P0030007\n",
      "P0030008\n",
      "OP00009\n",
      "OP00010\n",
      "OP00011\n",
      "OP00012\n",
      "P0040002\n",
      "P0040005\n",
      "P0040006\n",
      "P0040007\n",
      "P0040008\n",
      "P0040009\n",
      "P0040010\n",
      "OP000013\n",
      "OP000014\n",
      "OP000015\n",
      "OP000016\n",
      "H0010001\n",
      "H0010002\n",
      "H0010003\n",
      "ACRES\n",
      "Shape_Length\n",
      "Shape_Area\n",
      "SQMILES\n",
      "geometry\n"
     ]
    }
   ],
   "source": [
    "for column in census_blocks.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geojson version\n",
    "geojson_filename = Path(home, 'census_blocks.geojson')\n",
    "census_blocks.to_file(geojson_filename, driver='GeoJSON')\n",
    "data = open(geojson_filename, 'rb')\n",
    "s3.Bucket('dc-crash-bot-test').put_object(Key='census_blocks.geojson', Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import vision zero safety requests\n",
    "vision_zero = gpd.read_file('https://opendata.arcgis.com/datasets/3f28bc3ad77f49079efee0ac05d8464c_0.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all311_2020 = gpd.read_file('https://opendata.arcgis.com/datasets/82b33f4833284e07997da71d1ca7b1ba_11.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "GLOBALID\n",
      "REQUESTID\n",
      "REQUESTTYPE\n",
      "REQUESTDATE\n",
      "STATUS\n",
      "STREETSEGID\n",
      "COMMENTS\n",
      "USERTYPE\n",
      "geometry\n"
     ]
    }
   ],
   "source": [
    "for column in vision_zero.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "SERVICECODE\n",
      "SERVICECODEDESCRIPTION\n",
      "SERVICETYPECODEDESCRIPTION\n",
      "ORGANIZATIONACRONYM\n",
      "SERVICECALLCOUNT\n",
      "ADDDATE\n",
      "RESOLUTIONDATE\n",
      "SERVICEDUEDATE\n",
      "SERVICEORDERDATE\n",
      "INSPECTIONFLAG\n",
      "INSPECTIONDATE\n",
      "INSPECTORNAME\n",
      "SERVICEORDERSTATUS\n",
      "STATUS_CODE\n",
      "SERVICEREQUESTID\n",
      "PRIORITY\n",
      "STREETADDRESS\n",
      "XCOORD\n",
      "YCOORD\n",
      "LATITUDE\n",
      "LONGITUDE\n",
      "CITY\n",
      "STATE\n",
      "ZIPCODE\n",
      "MARADDRESSREPOSITORYID\n",
      "WARD\n",
      "DETAILS\n",
      "geometry\n"
     ]
    }
   ],
   "source": [
    "for column in all311_2020:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 311 data\n",
    "# import all 311 service requests in 2020\n",
    "all311_2020 = gpd.read_file('https://opendata.arcgis.com/datasets/82b33f4833284e07997da71d1ca7b1ba_11.geojson')\n",
    "# 2019\n",
    "all311_2019 = gpd.read_file('https://opendata.arcgis.com/datasets/98b7406def094fa59838f14beb1b8c81_10.geojson')\n",
    "# 2018\n",
    "all311_2018 = gpd.read_file('https://opendata.arcgis.com/datasets/2a46f1f1aad04940b83e75e744eb3b09_9.geojson')\n",
    "# 2017\n",
    "all311_2017 = gpd.read_file('https://opendata.arcgis.com/datasets/19905e2b0e1140ec9ce8437776feb595_8.geojson')\n",
    "# 2016\n",
    "all311_2016 = gpd.read_file('https://opendata.arcgis.com/datasets/0e4b7d3a83b94a178b3d1f015db901ee_7.geojson')\n",
    "# 2015\n",
    "all311_2015 = gpd.read_file('https://opendata.arcgis.com/datasets/b93ec7fc97734265a2da7da341f1bba2_6.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# limit all the 311 requests to just traffic safety assessments, and merge them\n",
    "tsa = all311_2020[all311_2020['SERVICECODEDESCRIPTION'] == 'Traffic Safety Investigation']\n",
    "print('2020: ', len(tsa))\n",
    "tsa = tsa.append(all311_2019[all311_2019['SERVICECODEDESCRIPTION'] == 'Traffic Safety Investigation'], ignore_index=True)\n",
    "print('2020 + 2019: ', len(tsa))\n",
    "tsa = tsa.append(all311_2018[all311_2018['SERVICECODEDESCRIPTION'] == 'Traffic Safety Investigation'], ignore_index=True)\n",
    "print('2020 + 2019 + 2018: ', len(tsa))\n",
    "tsa = tsa.append(all311_2017[all311_2017['SERVICECODEDESCRIPTION'] == 'Traffic Safety Investigation'], ignore_index=True)\n",
    "print('2020 + 2019 + 2018 + 2017: ', len(tsa))\n",
    "tsa = tsa.append(all311_2016[all311_2016['SERVICECODEDESCRIPTION'] == 'Traffic Safety Investigation'], ignore_index=True)\n",
    "print('2020 + 2019 + 2018 + 2017 + 2016: ', len(tsa))\n",
    "tsa = tsa.append(all311_2015[all311_2015['SERVICECODEDESCRIPTION'] == 'Traffic Safety Investigation'], ignore_index=True)\n",
    "print('2020 + 2019 + 2018 + 2017 + 2016 + 2015: ', len(tsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import crash details table\n",
    "crash_details = gpd.read_file('https://opendata.arcgis.com/datasets/70248b73c20f46b0a5ee895fc91d6222_25.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "CRIMEID\n",
      "CCN\n",
      "PERSONID\n",
      "PERSONTYPE\n",
      "AGE\n",
      "FATAL\n",
      "MAJORINJURY\n",
      "MINORINJURY\n",
      "VEHICLEID\n",
      "INVEHICLETYPE\n",
      "TICKETISSUED\n",
      "LICENSEPLATESTATE\n",
      "IMPAIRED\n",
      "SPEEDING\n",
      "geometry\n"
     ]
    }
   ],
   "source": [
    "for column in crash_details.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crash_details.PERSONTYPE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crash_details.MAJORINJURY.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crash_details.INVEHICLETYPE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# roll up crashes to crash id level\n",
    "# df.groupby('A').agg({ 'B': lambda x: list(x),'C': lambda x: list(x)})\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first create variables that will be aggregated\n",
    "# driver over 80/driver under 25 \n",
    "crash_details['DRIVERS_OVER_80']= crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Driver' \n",
    "                                                     and x.AGE>=80 else 0, axis = 1)\n",
    "crash_details['DRIVERS_UNDER_25']= crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Driver' \n",
    "                                                      and x.AGE<=25 else 0, axis = 1)\n",
    "# ped under 12/ped over 70 \n",
    "crash_details['PEDS_OVER_70']= crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Pedestrian' \n",
    "                                                     and x.AGE>=70 else 0, axis = 1)\n",
    "crash_details['PEDS_UNDER_12']= crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Pedestrian' \n",
    "                                                      and x.AGE<=12 else 0, axis = 1)\n",
    "# biker under 12/biker over 70\n",
    "crash_details['BIKERS_OVER_70']= crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Bicyclist' \n",
    "                                                     and x.AGE>=70 else 0, axis = 1)\n",
    "crash_details['BIKERS_UNDER_12']= crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Bicyclist' \n",
    "                                                      and x.AGE<=12 else 0, axis = 1)\n",
    "# out of state driver\n",
    "crash_details['OOS_VEHICLES']= crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Driver' \n",
    "                                                   and x.LICENSEPLATESTATE != 'DC' else 0, axis = 1)\n",
    "# vehicle type \n",
    "crash_details['CARS']=crash_details.apply(lambda x: 1 if x.INVEHICLETYPE=='Passenger Car/automobile' \n",
    "                                                    and x.PERSONTYPE=='Driver' else 0, axis = 1)\n",
    "crash_details['SUVS_OR_TRUCKS']=crash_details.apply(lambda x: 1 if (x.INVEHICLETYPE=='Suv (sport Utility Vehicle)'\n",
    "                                                     or x.  INVEHICLETYPE== 'Pickup Truck')\n",
    "                                                    and x.PERSONTYPE=='Driver' else 0, axis = 1)\n",
    "\n",
    "# injuries \n",
    "crash_details['PED_INJURIES']=crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Pedestrian' \n",
    "                                                   and (x.MAJORINJURY == 'Y' or x.MINORINJURY =='Y') else 0,\n",
    "                                                        axis = 1)\n",
    "crash_details['BICYCLE_INJURIES']=crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Bicyclist' \n",
    "                                                   and (x.MAJORINJURY == 'Y' or x.MINORINJURY =='Y') else 0,\n",
    "                                                        axis = 1)\n",
    "crash_details['VEHICLE_INJURIES']=crash_details.apply(lambda x: 1 if \n",
    "                                                      (x.PERSONTYPE=='Driver' or x.PERSONTYPE == 'Passenger')\n",
    "                                                   and (x.MAJORINJURY == 'Y' or x.MINORINJURY =='Y') else 0,\n",
    "                                                        axis = 1)\n",
    "# tickets issued? \n",
    "crash_details['DRIVER_TICKETS']=crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Driver' \n",
    "                                                   and x.TICKETISSUED == 'Y' else 0,\n",
    "                                                        axis = 1)\n",
    "crash_details['BICYCLE_TICKETS']=crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Bicyclist' \n",
    "                                                   and x.TICKETISSUED == 'Y' else 0,\n",
    "                                                        axis = 1)\n",
    "crash_details['PED_TICKETS']=crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Pedestrian' \n",
    "                                                   and x.TICKETISSUED == 'Y' else 0,\n",
    "                                                        axis = 1)\n",
    "# speeding? \n",
    "crash_details['DRIVERS_SPEEDING']=crash_details.apply(lambda x: 1 if x.PERSONTYPE=='Driver' \n",
    "                                                   and x.SPEEDING == 'Y' else 0,\n",
    "                                                        axis = 1)\n",
    "# total injuries\n",
    "crash_details['TOTAL_INJURIES']=crash_details['VEHICLE_INJURIES']+crash_details['BICYCLE_INJURIES']+crash_details['PED_INJURIES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crash_details_agg = (crash_details.groupby(['CRIMEID'])\n",
    "               .agg({\n",
    "                    'PED_INJURIES': 'sum', 'BICYCLE_INJURIES': 'sum','VEHICLE_INJURIES': 'sum'\n",
    "                     ,'TOTAL_INJURIES': 'sum', 'OOS_VEHICLES': 'sum', 'DRIVERS_UNDER_25': 'sum'\n",
    "                     , 'DRIVERS_OVER_80': 'sum', 'PEDS_OVER_70':'sum', 'PEDS_UNDER_12': 'sum'\n",
    "                   , 'BIKERS_OVER_70': 'sum', 'BIKERS_UNDER_12':'sum', 'OOS_VEHICLES': 'sum'\n",
    "                   ,'CARS' : 'sum', 'SUVS_OR_TRUCKS' : 'sum', 'DRIVER_TICKETS': 'sum'\n",
    "                   ,'BICYCLE_TICKETS': 'sum', 'PED_TICKETS':'sum', 'DRIVERS_SPEEDING': 'sum'\n",
    "                  ,'PERSONTYPE': lambda x: list(x), 'INVEHICLETYPE':  lambda x: list(x), \n",
    "                   'LICENSEPLATESTATE': lambda x: list(x)\n",
    "                    })\n",
    "               .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# join crashes to crash detail\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crash_details_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first add year to crashes\n",
    "crashes_raw['YEAR'] = crashes_raw.apply(lambda x: x.FROMDATE[:4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail =  crashes_raw.merge(crash_details_agg, how = 'left', on='CRIMEID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in crashes_w_detail.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes_w_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes_w_detail[(crashes_w_detail['LICENSEPLATESTATE'].isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail.geometry.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail.geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connection_string = urllib.parse.quote('{}:{}@{}:{}/{}'.format('postgresadmin','gWt7MuR%111N','dc-crash-bot-test.cw2qdhdq18cy.us-east-1.rds.amazonaws.com'\n",
    "                                                                                    ,5432,'postgres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connection_string_unencoded='postgresadmin:gWt7MuR%25111N@dc-crash-bot-test.cw2qdhdq18cy.us-east-1.rds.amazonaws.com:5432/postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "postgresql+psycopg2://user:password@host:port/dbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://'+connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://'+connection_string_unencoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail['geom'] = crashes_w_detail['geometry'].apply(lambda x: WKTElement(x.wkt, srid=4326))\n",
    "\n",
    "#drop the geometry column as it is now duplicative\n",
    "crashes_w_detail.drop('geometry', 1, inplace=True)\n",
    "\n",
    "# Use 'dtype' to specify column's type\n",
    "# For the geom column, we will use GeoAlchemy's type 'Geometry'\n",
    "# geodataframe.to_sql(table_name, engine, if_exists='append', index=False, \n",
    "#                          dtype={'geom': Geometry('POINT', srid= <your_srid>)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail = crashes_w_detail.set_geometry('geom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from psycopg2.extensions import adapt, register_adapter, AsIs\n",
    "from geoalchemy2.elements import WKBElement\n",
    "\n",
    "def WKBElementAdapter(element):\n",
    "    return AsIs(adapt(element.desc).getquoted())\n",
    "\n",
    "register_adapter(WKBElement, WKBElementAdapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from psycopg2.extensions import adapt, register_adapter, AsIs\n",
    "from geoalchemy2.elements import WKTElement\n",
    "\n",
    "def WKTElementAdapter(element):\n",
    "    return AsIs(adapt(element.desc).getquoted())\n",
    "\n",
    "register_adapter(WKTElement, WKTElementAdapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail2=crashes_w_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# another thing to try would just be to do this\n",
    "# df['location'] = \"POINT(\" + df['lng'].astype(str) + \" \" + df['lat'].astype(str) + \")\"\n",
    "# df.to_sql('table_name', engine, dtype={'location': Geometry(geometry_type='POINT', srid=4326)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail2['geom']=crashes_w_detail2['geom'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail2.to_sql('crashes_w_detail',engine,if_exists='replace', index=False,  chunksize=1000,\n",
    "                                     dtype={\n",
    "         'INVEHICLETYPE': postgresql.ARRAY(sqlalchemy.types.VARCHAR), \n",
    "         'PERSONTYPE':postgresql.ARRAY(sqlalchemy.types.VARCHAR),\n",
    "        'LICENSEPLATESTATE':postgresql.ARRAY(sqlalchemy.types.VARCHAR),\n",
    "     '\"geom\"': Geometry(geometry_type='POINT', srid= 4326)}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crashes_w_detail.to_sql('crashes_w_detail',engine,if_exists='replace', index=False,  \n",
    "                                     dtype={\n",
    "         'INVEHICLETYPE': postgresql.ARRAY(sqlalchemy.types.VARCHAR), \n",
    "         'PERSONTYPE':postgresql.ARRAY(sqlalchemy.types.VARCHAR),\n",
    "        'LICENSEPLATESTATE':postgresql.ARRAY(sqlalchemy.types.VARCHAR),\n",
    "     '\"geom\"': Geometry(geometry_type='POINT', srid= 4326)}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " crashes_w_detail.to_postgis(\n",
    "    con=engine,\n",
    "    name=\"crashes_w_detail\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# s = s.astype(str)\n",
    "# df[\"a\"] = pd.to_numeric(df[\"a\"])\n",
    "\n",
    "crashes_w_detail['PERSONTYPE']=crashes_w_detail['PERSONTYPE'].astype(str)\n",
    "crashes_w_detail['INVEHICLETYPE']=crashes_w_detail['INVEHICLETYPE'].astype(str)\n",
    "crashes_w_detail['LICENSEPLATESTATE']=crashes_w_detail['LICENSEPLATESTATE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_w_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# upload as a json and geojson to s3\n",
    "#######################################\n",
    "s3 = boto3.resource('s3')\n",
    "home = os.path.expanduser('~')\n",
    "\n",
    "# geojson version\n",
    "geojson_filename = Path(home, 'crashes_w_detail.geojson')\n",
    "crashes_w_detail.to_file(geojson_filename, driver='GeoJSON')\n",
    "data = open(geojson_filename, 'rb')\n",
    "s3.Bucket('dc-crash-bot-test').put_object(Key='crashes_w_detail.geojson', Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# csv version\n",
    "csv_filename = Path(home, 'crashes_w_detail.csv')\n",
    "crashes_w_detail.to_csv(csv_filename)\n",
    "data = open(csv_filename, 'rb')\n",
    "s3.Bucket('dc-crash-bot-test').put_object(Key='crashes_w_detail.csv', Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# merge census block into all datasets\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CRASHES\n",
    "# join crashes to data natively at census block level and add year\n",
    "# do both right and left joins\n",
    "census_blocks_crashes = gpd.sjoin(crashes_w_detail, census_blocks, how=\"left\", op='intersects')\n",
    "# census_blocks_crashes_right = gpd.sjoin(crashes_raw, census_blocks, how=\"right\", op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in census_blocks_crashes.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many crashes didn't join to a census block\n",
    "# crashes_null=census_blocks_crashes[(census_blocks_crashes['OBJECTID_right'].isnull()) & (census_blocks_crashes['YEAR'] == '2020')]\n",
    "crashes_null=census_blocks_crashes[(census_blocks_crashes['OBJECTID_right'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_blocks_crashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export null crashes to a csv file so i can check it out in a db\n",
    "crashes_null.to_csv('data/no_census_blocks/crashes_not_joining_to_census_block.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAFFIC SAFETY ASSESSMENT REQUESTS\n",
    "for column in tsa.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add year\n",
    "tsa['YEAR'] = tsa.apply(lambda x: x.ADDDATE[:4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_blocks_tsas = gpd.sjoin(tsa, census_blocks, how=\"left\", op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many TSAs didn't join to a census block\n",
    "census_blocks_tsas_null=census_blocks_tsas[(census_blocks_tsas['OBJECTID_right'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_blocks_tsas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_blocks_tsas_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export null TSAs to a csv file so i can check it out in a db\n",
    "census_blocks_tsas_null.to_csv('data/no_census_blocks/TSAs_not_joining_to_census_block.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VISION ZERO REQUESTS\n",
    "# first add year\n",
    "for column in vision_zero.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vision_zero['YEAR'] = vision_zero.apply(lambda x: x.REQUESTDATE[:4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_blocks_vision_zero = gpd.sjoin(vision_zero, census_blocks, how=\"left\", op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many vision zero requests didn't roll up to a census block\n",
    "census_blocks_vision_zero_null=census_blocks_vision_zero[(census_blocks_vision_zero['OBJECTID_right'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_blocks_vision_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_blocks_vision_zero_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export null records to a csv file so i can check it out in a db\n",
    "census_blocks_vision_zero_null.to_csv('data/no_census_blocks/VZ_Requests_not_joining_to_census_block.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# roll up by census block and year\n",
    "# Merge\n",
    "# Join back to census block dataset to get a geometry\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crashes data\n",
    "census_blocks_crashes['PED_INJURIES']=census_blocks_crashes[{'MAJORINJURIES_PEDESTRIAN','MINORINJURIES_PEDESTRIAN','UNKNOWNINJURIES_PEDESTRIAN'}].sum(axis=1)\n",
    "census_blocks_crashes['BICYCLE_INJURIES']=census_blocks_crashes[{'MAJORINJURIES_BICYCLIST','MINORINJURIES_BICYCLIST','UNKNOWNINJURIES_BICYCLIST'}].sum(axis=1)\n",
    "census_blocks_crashes['VEHICLE_INJURIES']=census_blocks_crashes[{'MAJORINJURIES_DRIVER','MINORINJURIES_DRIVER','UNKNOWNINJURIES_DRIVER','MAJORINJURIESPASSENGER','MINORINJURIESPASSENGER','UNKNOWNINJURIESPASSENGER'}].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_blocks_crashes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_blocks_crashes['TOTAL_INJURIES']=census_blocks_crashes[{'PED_INJURIES','BICYCLE_INJURIES','VEHICLE_INJURIES'}].sum(axis=1)\n",
    "census_blocks_crashes['TOTAL_FATALITIES']=census_blocks_crashes[{'FATAL_DRIVER','FATAL_BICYCLIST','FATAL_PEDESTRIAN','FATALPASSENGER'}].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_agg = (census_blocks_crashes.groupby(['OBJECTID_right', 'YEAR'])\n",
    "               .agg({'OBJECTID_left':'count'\n",
    "                     , 'PED_INJURIES': 'sum', 'BICYCLE_INJURIES': 'sum','VEHICLE_INJURIES': 'sum'\n",
    "                     ,'TOTAL_INJURIES': 'sum','TOTAL_FATALITIES': 'sum'\n",
    "                    ,'OOS_VEHICLES': 'sum', 'DRIVERS_UNDER_25': 'sum', 'DRIVERS_OVER_80': 'sum', \n",
    "                     'PEDS_OVER_70': 'sum', 'PEDS_UNDER_12': 'sum', 'BIKERS_OVER_70': 'sum', \n",
    "                     'BIKERS_UNDER_12': 'sum', 'CARS': 'sum', 'DRIVERS_OVER_80': 'sum', \n",
    "                     'SUVS_OR_TRUCKS': 'sum', 'DRIVER_TICKETS': 'sum', 'BICYCLE_TICKETS': 'sum', \n",
    "                     'PED_TICKETS': 'sum', 'DRIVERS_SPEEDING': 'sum', 'TOTAL_VEHICLES': 'sum', \n",
    "                    'TOTAL_BICYCLES': 'sum', 'TOTAL_PEDESTRIANS': 'sum'\n",
    "                    })\n",
    "               .reset_index().rename(columns={'OBJECTID_left':'TOTAL_CRASHES'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_agg.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TSA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_blocks_tsas_agg = (census_blocks_tsas.groupby(['OBJECTID_right', 'YEAR'])\n",
    "               .agg({'OBJECTID_left':'count'})\n",
    "               .reset_index().rename(columns={'OBJECTID_left':'TOTAL_TSA_REQUESTS'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_blocks_tsas_agg.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_blocks_tsas_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_tsas_agg = crashes_agg.merge(census_blocks_tsas_agg, how = 'left', on=['OBJECTID_right', 'YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes_tsas_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_tsas_agg.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vision zero data\n",
    "census_blocks_vision_zero_agg = (census_blocks_vision_zero.groupby(['OBJECTID_right', 'YEAR'])\n",
    "               .agg({'OBJECTID_left':'count'})\n",
    "               .reset_index().rename(columns={'OBJECTID_left':'TOTAL_VISION_ZERO_REQUESTS'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_tsas_vz_agg = crashes_tsas_agg.merge(census_blocks_vision_zero_agg, how = 'left', on=['OBJECTID_right', 'YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_tsas_vz_agg.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes_tsas_vz_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo_info = crashes_tsas_vz_agg.merge(census_blocks, how = 'inner', left_on = 'OBJECTID_right', right_on = 'OBJECTID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(geo_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo_info.geometry.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo_info = geo_info.set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo_info['geometry'].geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# census_blocks_addr = gpd.sjoin(address_points, census_blocks, how=\"left\", op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# roll up address points to census block, keeping one representative row for each census block\n",
    "census_blocks_addr = address_points.dissolve(by='CENSUS_BLOCK', aggfunc='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final = gpd.sjoin(geo_info, census_blocks_addr, how=\"left\", op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many vision zero requests didn't roll up to a census block\n",
    "final_null=final[(final['WARD'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_null.to_csv('data/no_census_blocks/census_blocks_w_crash_stats_not_joining_to_address.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_null.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final[(final['PEDS_UNDER_12']>0)].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final[(final['DRIVERS_OVER_80']>0)].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final.to_csv('data/merged/merged_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_2020 = final[final['YEAR'] == '2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_2020.to_file(\"data/merged/merged_v1_2020.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# PUT EVERYTHING IN AN S3 BUCKET\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geojson version\n",
    "geojson_filename = Path(home, 'census_block_level_final.geojson')\n",
    "final.to_file(geojson_filename, driver='GeoJSON')\n",
    "data = open(geojson_filename, 'rb')\n",
    "s3.Bucket('dc-crash-bot-test').put_object(Key='census_block_level_final.geojson', Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# csv version\n",
    "csv_filename = Path(home, 'census_block_level_final.csv')\n",
    "final.to_csv(csv_filename)\n",
    "data = open(csv_filename, 'rb')\n",
    "s3.Bucket('dc-crash-bot-test').put_object(Key='census_block_level_final.csv', Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# OLD CODE\n",
    "# keeping it to refer back to\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join crashes to data natively at ANC level and add year\n",
    "anc_crashes = gpd.sjoin(crashes_raw, ancs, how=\"inner\", op='within')\n",
    "anc_crashes['YEAR'] = anc_crashes.apply(lambda x: x.REPORTDATE[:4], axis=1)\n",
    "#Number of crashes thus far in 2020 by ANC\n",
    "pd.DataFrame(anc_crashes.groupby(['YEAR', 'NAME']).size()).loc['2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try to roll up address points to desired level\n",
    "# roll up address points to census block \n",
    "census_blocks = address_points.dissolve(by='CENSUS_BLOCK', aggfunc='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_blocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check geo type\n",
    "census_blocks['geometry'].geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove points so census blocks can be rolled up to polygons\n",
    "census_blocks=census_blocks[census_blocks['geometry'].geom_type != 'Point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check how many fell out\n",
    "len(census_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# limit the census blocks dataset to census blocks that can become polygons\n",
    "census_blocks = census_blocks[census_blocks['geometry'].apply(lambda x: len(list(x)) > 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_block_polygons=census_blocks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to polygons\n",
    "census_block_polygons['geometry'] = census_block_polygons.apply(lambda x: Polygon(x.geometry), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(census_block_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# roll up crashes by census block\n",
    "crashes = gpd.sjoin(crashes_raw, census_block_polygons, how=\"left\", op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes['YEAR'] = crashes.apply(lambda x: x.REPORTDATE[:4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do a sanity check on number of crashes by year and ward\n",
    "ward_year_rollup=pd.DataFrame(crashes.fillna(-1).groupby(['YEAR', 'WARD_right', 'WARD_left']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ward_year_rollup.to_excel('crashes_by_year_and_ward.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many crashes in 2020 didn't join to a census block\n",
    "crashes_null=crashes[(crashes['WARD_right'].isnull()) & (crashes['YEAR'] == '2020')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(crashes_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check distance between address points objectid 846387/MARID 15323 and all of the crashes listed at that MARID\n",
    "crash_sample = crashes_raw.loc[crashes_raw['MARID'] == 15232]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addr_sample = address_points.loc[address_points['ADDRESS_ID'] == 15232]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for point in crash_sample['geometry']:\n",
    "    print(point.distance(addr_sample['geometry'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "address_points_buf = address_points.copy()\n",
    "address_points_buf['geometry'] = address_points_buf.apply(lambda x: x.geometry.buffer(0.0003), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crashbot venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
